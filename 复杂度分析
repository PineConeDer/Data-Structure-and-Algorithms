 复杂度分析是整个数据结构和算法学习的精髓，只要掌握了它，数据结构和算法的内容也就掌握了一半。我们所写的代码都应该考虑算法执行的时间和空间占用的内存大小，
 复杂度分析可以粗略地估计算法的执行效率的方法。
 大O复杂度分析表示法：
    从CPU的角度讲，每一行代码都执行这相似的操作：读数据-运算-写数据。我们可以粗略估计，可以假设每行代码执行的时间是一样的，都是unit_time,那么一段代码的
 总执行时间T(n)与每行代码的执行次数成正比。
    T(n) = O(f(n))
    T(n)表示代码执行的时间；n表示数据规模的大小；f(n)表示每行代码执行次数的总和。O表示T(n)和f(n)成正比；
    大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间对数据规模增长的变化趋势，所以也叫作渐进时间复杂度。
    比如：T(n) = O(2n+2), T(n) = O(2n^2 + 2n + 3) 当n很大时，比如10000、100000，公式中的低阶，常量，系数并不会左右增长趋势，所以可以忽略，只需记录一
 个最大量级就可以了。T(n) = O(n), T(n) = O(n^2)
 
 如何分析一段代码的时间复杂度：
    1.只关注循环次数最多的一段代码
    2.加法法则：总复杂度等于量级最大的代码的复杂度。
               T1(n) = O(f(n)), T2(n) = O(g(n))；那么T(n) = T1(n) + T2(n) = max(O(f(n)),O(g(n))) = O(max(f(n),g(n))).
    3.乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。
               T1(n) = O(f(n)), T2(n) = O(g(n))；那么T(n) = T1(n) * T2(n) = O(f(n))*O(g(n)) = O(f(n)*g(n)).
       
 几种常见时间复杂度分析：
    多项式量级：常量阶 O(1) 、对数阶 O(logn)、线性阶 O(n)、线性对数阶 O(nlogn)、平方阶 O(n^2)、立方阶 O(n^3)、k次方阶 O(n^k)。
    非多项式量级：指数阶 O(2^n)、阶乘阶 O(n!)
    当数据规模n越来越大时，非多项式量级算法的执行时间会急剧增加，所以非多项式时间复杂度的算法其实是非常低效的算法。
 O(1) 一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万的代码，其时间复杂度也是O(1)。
 O(logn)、O(nlogn) 对数阶复杂度非常常见，同时也是最难分析的一种时间复杂度。
      i = 1；
      while（i <= n）{
            i = i * 2;
      }
      这个就想相当于2^0, 2^1, 2^2, 2^3, 2^k, ....2^x = n,其实就是一个等比数列，那么x = log2^n。当 i = i * 3时， x = log3^n
      不管以2为底，还是以3为底，以10为底，对数之间可以互相转换的，所以都可以把所有对数阶的复杂度记为O(logn).
      一段代码的时间复杂度是O(logn)，我们循环执行n遍就是O(nlogn)。
  O(m+n)、O(m * n) 代码的复杂度由两个数据的规模来决定。加法法则和乘法法则。
  
  空间复杂度分析：
  空间复杂度就是算法的储存空间与数据规模之间的增长关系。常见的空间复杂度就是O(1)、O(n)、O(n^2)，像O(logn)、O(nlogn)对数阶复杂度平时都用不到。
  
  
      
      

   
  
    
    
